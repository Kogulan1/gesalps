# Run Structure and User Experience Analysis

## Executive Summary

This document analyzes how "runs" (synthetic data generation executions) are structured, stored, and presented to users in both the backend and frontend. It highlights what agent reasoning and decision-making information is visible vs. hidden from users.

---

## Backend: Run Structure & Storage

### Database Schema (`backend/sql/schema.sql`)

**Core Tables:**

1. **`runs` table** - Main run record:
   - `id` (UUID, primary key)
   - `project_id`, `dataset_id`, `started_by` (foreign keys)
   - `method` (text) - e.g., "gc", "ctgan", "tvae"
   - `mode` (text) - "agent" | "custom" | "auto-benchmark"
   - `status` (enum) - `'queued'` | `'running'` | `'succeeded'` | `'failed'`
   - `started_at`, `finished_at` (timestamps)
   - `config_json` (JSONB) - **Stores agent plan, preferences, hyperparameters**
   - `logs_url` (optional)

2. **`run_steps` table** - Step-by-step execution log:
   - `run_id`, `step_no` (int), `title` (text), `detail` (text)
   - `metrics_json` (JSONB) - Metrics at each step
   - `created_at` (timestamp)

3. **`metrics` table** - Final run metrics:
   - `run_id` (foreign key, primary key)
   - `payload_json` (JSONB) - Complete metrics including utility, privacy, fairness

4. **`run_artifacts` table** - Generated files:
   - `run_id`, `kind` (e.g., "synthetic_csv", "report_json", "report_pdf")
   - `path`, `bytes`, `mime`

### Run Creation Flow (`backend/api/main.py`)

**Endpoint:** `POST /v1/runs`

1. **Planning Phase (lines 671-696):**
   - If `mode == "agent"`: Calls `_agent_plan_internal()` to generate plan via LLM
   - Plan structure stored in `config_json.plan`:
     ```json
     {
       "choice": {"method": "gc", "hyperparams": {...}},
       "backup": [{"method": "ctgan", ...}, {"method": "tvae", ...}],
       "rationale": "explanation text",
       "dp": {"enabled": false},
       "hyperparams": {...}
     }
     ```
   - If `mode == "custom"`: Creates minimal plan with user's method choice
   - If `mode == "auto-benchmark"`: Plan is generated during execution

2. **Run Insertion (lines 760-777):**
   - Inserts run with `status='queued'`
   - Initial step logged: `step_no=0, title="planned", detail="method=..."`

3. **Worker Processing (`backend/synth_worker/worker.py`):**

   **Plan-Driven Execution (lines 985-1060):**
   - Reads `config_json.plan` from run
   - Executes attempts in order: `choice` → `backup[0]` → `backup[1]`
   - For each attempt, logs steps:
     - `step_no=i, title="training", detail="attempt {i}: method={method}"`
     - `step_no=i, title="metrics", detail="{threshold reasons}", metrics_json={metrics}`
     - `step_no=i, title="error", detail="{error}"` (if failed)
   - Stops at first attempt that passes thresholds
   - Falls back to best-scoring attempt if none pass

   **Agent Re-planning (lines 1336-1372):**
   - During execution, if metrics don't meet thresholds, agent can re-plan
   - Logs: `title="Agent suggestion", detail="method={method}; hparams={...}; {notes}"`

   **Heuristic Fallback (lines 1115-1292):**
   - If no plan exists, uses schema heuristics
   - Logs: `title="Heuristic init", detail="numeric_ratio={ratio} → {method}"`

4. **Step Logging (`_log_step` function, lines 937-947):**
   ```python
   def _log_step(step_no, title, detail, metrics_json):
       supabase.table("run_steps").insert({
           "run_id": run_id,
           "step_no": step_no,
           "title": title,      # e.g., "planned", "training", "metrics", "error"
           "detail": detail,     # Human-readable description
           "metrics_json": metrics_json  # Optional metrics snapshot
       })
   ```

5. **Final Metrics Storage (lines 1556-1559):**
   - After successful completion, metrics saved to `metrics` table
   - Artifacts (CSV, JSON, PDF) saved to `run_artifacts` table

### Agent Decision Storage

**Location:** `runs.config_json.plan`

**Structure:**
```json
{
  "choice": {
    "method": "gc|ctgan|tvae",
    "hyperparams": {
      "epochs": 100,
      "batch_size": 128,
      "embedding_dim": 64
    }
  },
  "backup": [
    {"method": "ctgan", "hyperparams": {...}},
    {"method": "tvae", "hyperparams": {...}}
  ],
  "rationale": "Explanation of why this method was chosen based on dataset characteristics",
  "dp": {"enabled": false, "epsilon": null},
  "hyperparams": {...}
}
```

**Generated by:**
- `_agent_plan_internal()` in API (for initial planning)
- `_agent_plan_ollama()` in worker (for re-planning during execution)

**Key Fields:**
- **`choice`**: Primary method selection with rationale
- **`backup`**: Fallback methods if primary fails
- **`rationale`**: **Agent's reasoning - currently stored but not prominently displayed in UI**
- **`hyperparams`**: Model-specific parameters

---

## Frontend: Run Display & User Experience

### Main Components

#### 1. **RunsContent** (`frontend/components/runs/RunsContent.tsx`)

**Purpose:** Main list view of all runs, grouped by project → dataset → runs

**Displays:**
- Run name, status badge (colored)
- **Metric indicators**: Small colored bars for privacy (MIA AUC, dup rate) and utility (KS mean, corr delta)
- Action buttons: View, Download, More (rename/archive/delete)

**What's Visible:**
- ✅ Status (queued/running/succeeded/failed) with color coding
- ✅ Basic metrics as visual indicators (bars)
- ✅ Duration, started/finished times
- ✅ Project/dataset context

**What's Hidden:**
- ❌ Agent plan/rationale
- ❌ Step-by-step execution log
- ❌ Backup method attempts
- ❌ Agent reasoning for method selection

**API:** `GET /dev/runs` (returns runs with metadata, but no steps or plan details)

#### 2. **RunStatus** (`frontend/components/runs/RunStatus.tsx`)

**Purpose:** Status badge component

**Displays:**
- Color-coded badge: `queued` (gray), `running` (yellow), `succeeded` (green), `failed` (red)

#### 3. **RunStepper** (`frontend/components/runs/RunStepper.tsx`)

**Purpose:** Visual progress stepper

**Steps:** `queued` → `running` → `synthesizing` → `evaluating` → `completed`

**Mapping Logic (`mapStatusToStep`):**
- `status='queued'` → `queued`
- `status='running'` → `running` or `synthesizing` (if `inTraining` flag exists)
- `status='succeeded'` → `evaluating` (if no metrics yet) or `completed`
- `status='failed'` → `failed`

**What's Visible:**
- ✅ High-level progress through stages
- ✅ Current step highlighted

**What's Hidden:**
- ❌ Actual step details from `run_steps` table
- ❌ Which method is being trained
- ❌ Why method was chosen or changed

#### 4. **RealTimeRunStatus** (`frontend/components/runs/RealTimeRunStatus.tsx`)

**Purpose:** Real-time status card for active runs

**Displays:**
- Status icon, name, badges (Live/Polling)
- Progress bar (when running)
- Current step text
- Duration
- **Metrics preview**: Utility (KS mean, Corr Δ) and Privacy (MIA AUC, Dup rate)

**Features:**
- Polls `/api/v1/runs/{runId}/status` every 2 seconds
- WebSocket support (commented out)

**What's Visible:**
- ✅ Current metrics (if available)
- ✅ Progress indication
- ✅ Duration

**What's Hidden:**
- ❌ Agent plan
- ❌ Step history
- ❌ Method selection rationale

#### 5. **ResultsModal** (`frontend/components/runs/ResultsModal.tsx`)

**Purpose:** Detailed view of completed run results

**Tabs:**
1. **Overview**: Run details, overall scores (AUROC, C-Index, Privacy Score, Utility Score), download buttons
2. **Metrics**: Privacy audit (MIA AUC, dup rate) and Utility audit (KS mean, corr delta) with pass/fail status
3. **Privacy**: Detailed privacy metrics with progress bars
4. **Utility**: Detailed utility metrics with progress bars

**What's Visible:**
- ✅ Final metrics in detail
- ✅ Pass/fail status for audits
- ✅ Visual progress bars for metrics
- ✅ Method name
- ✅ Download options

**What's Hidden:**
- ❌ Agent plan (choice, backup, rationale)
- ❌ Execution steps/history
- ❌ Which backup methods were tried
- ❌ Why method was selected

**API:** Currently uses mock data; should fetch from `/v1/runs/{runId}/metrics` and `/v1/runs/{runId}/artifacts`

### API Endpoints Available

1. **`GET /v1/runs`** - List all runs (includes metadata, but minimal detail)
2. **`GET /v1/runs/{runId}/metrics`** - Get metrics JSON
3. **`GET /v1/runs/{runId}/artifacts`** - Get artifact paths
4. **`GET /v1/runs/{runId}/steps`** - **Get step-by-step log** ⭐ (exists but not used in UI)

### Missing UI Components

**No components exist to display:**
- Agent plan (`config_json.plan`) - choice, backup, rationale
- Step history from `run_steps` table
- Agent re-planning decisions during execution
- Method selection reasoning

---

## Summary: What Users See vs. What's Hidden

### ✅ **VISIBLE TO USERS:**

1. **Status Information:**
   - Run status (queued/running/succeeded/failed) with color badges
   - High-level progress stepper (queued → synthesizing → evaluating → completed)
   - Duration and timestamps

2. **Final Results:**
   - Method name (e.g., "gc", "ctgan", "tvae")
   - Final metrics: Utility (KS mean, corr delta), Privacy (MIA AUC, dup rate)
   - Pass/fail status for audits
   - Downloadable artifacts (CSV, PDF report)

3. **Visual Indicators:**
   - Small colored bars for metric quality
   - Progress bars in detailed views
   - Status icons (checkmark, clock, X, etc.)

### ❌ **HIDDEN FROM USERS:**

1. **Agent Reasoning:**
   - **`plan.rationale`** - Why the agent chose a method
   - **`plan.choice`** - Primary method selection with hyperparameters
   - **`plan.backup`** - Fallback methods if primary fails
   - Agent re-planning during execution (why method was changed)

2. **Execution Details:**
   - **Step-by-step log** from `run_steps` table (API exists: `/v1/runs/{runId}/steps` but not displayed)
   - Which backup methods were attempted
   - Why a method failed and fallback was used
   - Training progress details

3. **Decision History:**
   - Initial plan vs. re-planning decisions
   - Threshold failures and retries
   - Heuristic method selection details

---

## Recommendations

### High Priority: Make Agent Reasoning Visible

1. **Add "Agent Plan" Tab/Section** to ResultsModal:
   - Display `config_json.plan.rationale` in readable format
   - Show primary choice and backup methods
   - Indicate which method actually succeeded

2. **Add "Execution Log" Tab** to ResultsModal:
   - Fetch from `/v1/runs/{runId}/steps`
   - Display step-by-step: training attempts, metrics, errors, agent suggestions
   - Show timeline of decisions

3. **Enhance RunStepper**:
   - Show actual method name at each step
   - Indicate when backup method is being tried
   - Show agent suggestions inline

### Medium Priority: Real-time Visibility

4. **Enhance RealTimeRunStatus**:
   - Show current method being trained
   - Display recent step logs
   - Show agent suggestions as they occur

5. **Add "Planning" Step**:
   - Show initial agent plan before execution starts
   - Display rationale immediately after planning

### Low Priority: Advanced Features

6. **Comparison View**:
   - Compare metrics across different backup attempts
   - Show why backup was used vs. primary

7. **Agent Insights Panel**:
   - Summary of agent's decision-making process
   - Key factors that influenced method selection

---

## Technical Notes

### Current State:
- ✅ Backend fully logs agent decisions and steps
- ✅ API endpoint exists to fetch steps (`/v1/runs/{runId}/steps`)
- ✅ Plan structure is comprehensive (choice, backup, rationale)
- ❌ Frontend does not display any of this information
- ❌ No UI component to show agent reasoning or execution history

### Data Flow:
```
User Creates Run
  ↓
API Generates Plan → Stores in config_json.plan
  ↓
Worker Executes Plan → Logs Steps to run_steps
  ↓
Metrics Saved → metrics.payload_json
  ↓
Frontend Displays → Status, Final Metrics Only (plan & steps hidden)
```

**Gap:** Rich agent decision data exists in backend but is not surfaced in UI.

